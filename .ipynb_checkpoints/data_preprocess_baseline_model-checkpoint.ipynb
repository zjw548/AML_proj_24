{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2109a54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "import time\n",
    "from sklearn.preprocessing import OrdinalEncoder,OneHotEncoder\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV,GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_validate\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from scipy.stats import uniform\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc85277c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "def fxn():\n",
    "    warnings.warn(\"deprecated\", DeprecationWarning)\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    fxn()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70429a69",
   "metadata": {},
   "source": [
    "## Two datasets\n",
    "\n",
    "1. Original unencoded. We would scale and encode in our own methods.\n",
    "\n",
    "2. Encoded numerical. We would use it as a comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f48478d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of original dataset:  (1884, 32)\n",
      "Shape of quantified dataset:  (1884, 32)\n"
     ]
    }
   ],
   "source": [
    "df_original = pd.read_csv(\"Drug_Consumption.csv\")\n",
    "df_quantified = pd.read_csv(\"Drug_Consumption_Quantified.csv\")\n",
    "\n",
    "print(\"Shape of original dataset: \", df_original.shape)\n",
    "print(\"Shape of quantified dataset: \", df_quantified.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "761235b9",
   "metadata": {},
   "source": [
    "## Quantified dataset preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "794fef43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1876, 30)\n"
     ]
    }
   ],
   "source": [
    "df = df_quantified.drop(['ID'],axis=1)\n",
    "df = df[df['Semer']=='CL0']\n",
    "df = df.drop(['Semer'],axis=1)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7dda565c",
   "metadata": {},
   "outputs": [],
   "source": [
    "drugs_to_ignore = ['Amphet', 'Amyl', 'Benzos', 'Ketamine', 'Legalh', 'Meth', 'VSA']\n",
    "drugs_to_consider = ['Alcohol', 'Caff', 'Cannabis', 'Choc', 'Coke', 'Crack', 'Ecstasy', 'Heroin', 'LSD', 'Mushrooms', 'Nicotine']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "220d8fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_alcohol_feature = drugs_to_ignore + ['Caff', 'Cannabis', 'Choc', 'Coke', 'Crack', 'Ecstasy', 'Heroin', 'LSD', 'Mushrooms', 'Nicotine']\n",
    "non_caff_features = drugs_to_ignore + ['Alcohol', 'Cannabis', 'Choc', 'Coke', 'Crack', 'Ecstasy', 'Heroin', 'LSD', 'Mushrooms', 'Nicotine']\n",
    "non_cannabis_features = drugs_to_ignore + ['Alcohol', 'Caff', 'Choc', 'Coke', 'Crack', 'Ecstasy', 'Heroin', 'LSD', 'Mushrooms', 'Nicotine']\n",
    "non_choc_features = drugs_to_ignore + ['Alcohol', 'Caff', 'Cannabis', 'Coke', 'Crack', 'Ecstasy', 'Heroin', 'LSD', 'Mushrooms', 'Nicotine']\n",
    "non_coke_features = drugs_to_ignore + ['Alcohol', 'Caff', 'Cannabis', 'Choc', 'Crack', 'Ecstasy', 'Heroin', 'LSD', 'Mushrooms', 'Nicotine']\n",
    "non_crack_features = drugs_to_ignore + ['Alcohol', 'Caff', 'Cannabis', 'Choc', 'Coke', 'Ecstasy', 'Heroin', 'LSD', 'Mushrooms', 'Nicotine']\n",
    "non_ecstasy_features = drugs_to_ignore + ['Alcohol', 'Caff', 'Cannabis', 'Choc', 'Coke', 'Crack', 'Heroin', 'LSD', 'Mushrooms', 'Nicotine']\n",
    "non_heroin_features = drugs_to_ignore + ['Alcohol', 'Caff', 'Cannabis', 'Choc', 'Coke', 'Crack', 'Ecstasy', 'LSD', 'Mushrooms', 'Nicotine']\n",
    "non_lsd_features = drugs_to_ignore + ['Alcohol', 'Caff', 'Cannabis', 'Choc', 'Coke', 'Crack', 'Ecstasy', 'Heroin', 'Mushrooms', 'Nicotine']\n",
    "non_mushrooms_features = drugs_to_ignore + ['Alcohol', 'Caff', 'Cannabis', 'Choc', 'Coke', 'Crack', 'Ecstasy', 'Heroin', 'LSD', 'Nicotine']\n",
    "non_nicotine_features = drugs_to_ignore + ['Alcohol', 'Caff', 'Cannabis', 'Choc', 'Coke', 'Crack', 'Ecstasy', 'Heroin', 'LSD', 'Mushrooms']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9507b3a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "drug_enc=OrdinalEncoder(categories=[[\"CL0\",\"CL1\",\"CL2\",\"CL3\",\"CL4\",\"CL5\",\"CL6\"]])\n",
    "for feature in drugs_to_consider:\n",
    "    df[feature]=drug_enc.fit_transform(df[feature].to_numpy().reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c94db373",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_quan_alcohol = df.drop(non_alcohol_feature, axis = 1)\n",
    "\n",
    "df_quan_caff = df.drop(non_caff_features, axis = 1)\n",
    "\n",
    "df_quan_cannabis = df.drop(non_cannabis_features, axis = 1)\n",
    "\n",
    "df_quan_choc = df.drop(non_choc_features, axis = 1)\n",
    "\n",
    "df_quan_coke = df.drop(non_coke_features, axis = 1)\n",
    "\n",
    "df_quan_crack = df.drop(non_crack_features, axis = 1)\n",
    "\n",
    "df_quan_ecstasy = df.drop(non_ecstasy_features, axis = 1)\n",
    "\n",
    "df_quan_heroin = df.drop(non_heroin_features, axis = 1)\n",
    "\n",
    "df_quan_lsd = df.drop(non_lsd_features, axis = 1)\n",
    "\n",
    "df_quan_mushrooms = df.drop(non_mushrooms_features, axis = 1)\n",
    "\n",
    "df_quan_nicotine = df.drop(non_nicotine_features, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "81ed7605",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Education</th>\n",
       "      <th>Country</th>\n",
       "      <th>Ethnicity</th>\n",
       "      <th>Nscore</th>\n",
       "      <th>Escore</th>\n",
       "      <th>Oscore</th>\n",
       "      <th>AScore</th>\n",
       "      <th>Cscore</th>\n",
       "      <th>Impulsive</th>\n",
       "      <th>SS</th>\n",
       "      <th>Nicotine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.07854</td>\n",
       "      <td>-0.48246</td>\n",
       "      <td>1.98437</td>\n",
       "      <td>0.96082</td>\n",
       "      <td>-0.31685</td>\n",
       "      <td>-0.67825</td>\n",
       "      <td>1.93886</td>\n",
       "      <td>1.43533</td>\n",
       "      <td>0.76096</td>\n",
       "      <td>-0.14277</td>\n",
       "      <td>-0.71126</td>\n",
       "      <td>-0.21575</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.49788</td>\n",
       "      <td>-0.48246</td>\n",
       "      <td>-0.05921</td>\n",
       "      <td>0.96082</td>\n",
       "      <td>-0.31685</td>\n",
       "      <td>-0.46725</td>\n",
       "      <td>0.80523</td>\n",
       "      <td>-0.84732</td>\n",
       "      <td>-1.62090</td>\n",
       "      <td>-1.01450</td>\n",
       "      <td>-1.37983</td>\n",
       "      <td>0.40148</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.95197</td>\n",
       "      <td>0.48246</td>\n",
       "      <td>1.16365</td>\n",
       "      <td>0.96082</td>\n",
       "      <td>-0.31685</td>\n",
       "      <td>-0.14882</td>\n",
       "      <td>-0.80615</td>\n",
       "      <td>-0.01928</td>\n",
       "      <td>0.59042</td>\n",
       "      <td>0.58489</td>\n",
       "      <td>-1.37983</td>\n",
       "      <td>-1.18084</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.49788</td>\n",
       "      <td>0.48246</td>\n",
       "      <td>1.98437</td>\n",
       "      <td>0.96082</td>\n",
       "      <td>-0.31685</td>\n",
       "      <td>0.73545</td>\n",
       "      <td>-1.63340</td>\n",
       "      <td>-0.45174</td>\n",
       "      <td>-0.30172</td>\n",
       "      <td>1.30612</td>\n",
       "      <td>-0.21712</td>\n",
       "      <td>-0.21575</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.59171</td>\n",
       "      <td>0.48246</td>\n",
       "      <td>-1.22751</td>\n",
       "      <td>0.24923</td>\n",
       "      <td>-0.31685</td>\n",
       "      <td>-0.67825</td>\n",
       "      <td>-0.30033</td>\n",
       "      <td>-1.55521</td>\n",
       "      <td>2.03972</td>\n",
       "      <td>1.63088</td>\n",
       "      <td>-1.37983</td>\n",
       "      <td>-1.54858</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Age   Gender  Education  Country  Ethnicity   Nscore   Escore   Oscore  \\\n",
       "0 -0.07854 -0.48246    1.98437  0.96082   -0.31685 -0.67825  1.93886  1.43533   \n",
       "1  0.49788 -0.48246   -0.05921  0.96082   -0.31685 -0.46725  0.80523 -0.84732   \n",
       "2 -0.95197  0.48246    1.16365  0.96082   -0.31685 -0.14882 -0.80615 -0.01928   \n",
       "3  0.49788  0.48246    1.98437  0.96082   -0.31685  0.73545 -1.63340 -0.45174   \n",
       "4  2.59171  0.48246   -1.22751  0.24923   -0.31685 -0.67825 -0.30033 -1.55521   \n",
       "\n",
       "    AScore   Cscore  Impulsive       SS  Nicotine  \n",
       "0  0.76096 -0.14277   -0.71126 -0.21575       4.0  \n",
       "1 -1.62090 -1.01450   -1.37983  0.40148       0.0  \n",
       "2  0.59042  0.58489   -1.37983 -1.18084       2.0  \n",
       "3 -0.30172  1.30612   -0.21712 -0.21575       2.0  \n",
       "4  2.03972  1.63088   -1.37983 -1.54858       6.0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_quan_nicotine.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0493678c",
   "metadata": {},
   "source": [
    "## Original dataset preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "19b8b555",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1876, 23)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = df_original.drop(['ID'],axis=1)\n",
    "df1 = df1[df1['Semer']=='CL0']\n",
    "df1 = df1.drop(['Semer'],axis=1)\n",
    "df1 = df1.drop(drugs_to_ignore,axis=1)\n",
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "88fb09b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_feature = ['Nscore','Escore','Oscore','AScore','Cscore','Impulsive','SS']\n",
    "nominal_cat_feature=[\"Gender\",\"Country\",\"Ethnicity\"] ##apply onehot encoder to encode nominal categorical features\n",
    "\n",
    "## apply ordinalecoder to encode ordinal categorical features and target values.\n",
    "age_enc=OrdinalEncoder(categories=[[\"18-24\",\"25-34\",\"35-44\",\"45-54\",\"55-64\",\"65+\"]])\n",
    "edu_enc=OrdinalEncoder(categories=[[\"Left school before 16 years\",\"Left school at 16 years\",\"Left school at 17 years\",\"Left school at 18 years\",\"Some college or university, no certificate or degree\",\"Professional certificate/ diploma\",\"University degree\",\"Masters degree\",\"Doctorate degree\"]])\n",
    "drug_enc=OrdinalEncoder(categories=[[\"CL0\",\"CL1\",\"CL2\",\"CL3\",\"CL4\",\"CL5\",\"CL6\"]])\n",
    "\n",
    "## ordinal encoder seems not encode multiple varibles at same time, so encode targets values one by one first.\n",
    "for feature in drugs_to_consider:\n",
    "    df1[feature] = drug_enc.fit_transform(df1[feature].to_numpy().reshape(-1,1))\n",
    "\n",
    "preprocess=make_column_transformer((StandardScaler(),numerical_feature),\n",
    "                                   (age_enc,[\"Age\"]),\n",
    "                                   (edu_enc, [\"Education\"]),\n",
    "                                   (OneHotEncoder(handle_unknown=\"ignore\",drop='first'),nominal_cat_feature),\n",
    "                                   remainder=\"passthrough\")\n",
    "df_trans = preprocess.fit_transform(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3ba3c71e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1876, 33)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_trans.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2120a0ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1876, 22)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ori_X = df_trans[:,:22]\n",
    "df_ori_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7721d6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ori_alcohol = np.c_[df_ori_X,df_trans[:,22]]\n",
    "\n",
    "df_ori_caff = np.c_[df_ori_X,df_trans[:,23]]\n",
    "\n",
    "df_ori_cannabis = np.c_[df_ori_X,df_trans[:,24]]\n",
    "\n",
    "df_ori_choc = np.c_[df_ori_X,df_trans[:,25]]\n",
    "\n",
    "df_ori_coke = np.c_[df_ori_X,df_trans[:,26]]\n",
    "\n",
    "df_ori_crack = np.c_[df_ori_X,df_trans[:,27]]\n",
    "\n",
    "df_ori_ecstasy = np.c_[df_ori_X,df_trans[:,28]]\n",
    "\n",
    "df_ori_heroin = np.c_[df_ori_X,df_trans[:,29]]\n",
    "\n",
    "df_ori_lsd = np.c_[df_ori_X,df_trans[:,30]]\n",
    "\n",
    "df_ori_mushrooms = np.c_[df_ori_X,df_trans[:,31]]\n",
    "\n",
    "df_ori_nicotine = np.c_[df_ori_X,df_trans[:,32]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2933cebf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1876, 23)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ori_alcohol.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50989268",
   "metadata": {},
   "source": [
    "## modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9316c091",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(df_X, df_Y):\n",
    "    X_dev, X_test, y_dev, y_test = train_test_split(df_X, df_Y, test_size=0.2, random_state=42)\n",
    "    return X_dev,X_test,y_dev,y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cd019fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "quantified_df = [df_quan_alcohol, df_quan_caff, df_quan_cannabis, df_quan_choc, df_quan_coke, df_quan_crack,\\\n",
    "                  df_quan_ecstasy, df_quan_heroin, df_quan_lsd, df_quan_mushrooms, df_quan_nicotine]\n",
    "original_df = [df_ori_alcohol, df_ori_caff, df_ori_cannabis, df_ori_choc, df_ori_coke, df_ori_crack,\\\n",
    "                  df_ori_ecstasy, df_ori_heroin, df_ori_lsd, df_ori_mushrooms, df_ori_nicotine]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "31c8dded",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.0    805\n",
       "5.0    679\n",
       "4.0    295\n",
       "3.0     53\n",
       "0.0     32\n",
       "2.0     10\n",
       "1.0      2\n",
       "Name: Choc, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_quan_choc['Choc'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e63c2c57",
   "metadata": {},
   "source": [
    "## Logistic Regression Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f5206124",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alcohol\n",
      "original dataset\n",
      "train acc 0.4318772136953955 test acc 0.22074468085106383\n",
      "test confusion matrix\n",
      " [[ 3  2  0  0  1  1  0]\n",
      " [ 2  1  1  0  1  0  2]\n",
      " [ 0  0  2  5  1  1  3]\n",
      " [ 4  6  4 13  7  5  3]\n",
      " [ 6 11  8 13 10 15  1]\n",
      " [15 24  9 23 16 35 30]\n",
      " [ 8 20 11 10 13 11 19]]\n",
      "test macro F1 0.17719972160315964\n",
      "test micro F1 0.22074468085106383\n",
      "test weighted F1 0.25386015020942554\n",
      "Caff\n",
      "original dataset\n",
      "train acc 0.44022794974744206 test acc 0.1595744680851064\n",
      "Cannabis\n",
      "original dataset\n",
      "train acc 0.3709550118389897 test acc 0.3484042553191489\n",
      "Choc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zhouj\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:684: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original dataset\n",
      "train acc 0.22866666666666666 test acc 0.17819148936170212\n",
      "Coke\n",
      "original dataset\n",
      "train acc 0.44391534391534393 test acc 0.35904255319148937\n",
      "Crack\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zhouj\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:684: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original dataset\n",
      "train acc 0.488 test acc 0.449468085106383\n",
      "Ecstasy\n",
      "original dataset\n",
      "train acc 0.4023542001070091 test acc 0.3776595744680851\n",
      "Heroin\n",
      "original dataset\n",
      "train acc 0.5470575022461814 test acc 0.5106382978723404\n",
      "LSD\n",
      "original dataset\n",
      "train acc 0.5801169590643275 test acc 0.4973404255319149\n",
      "Mushrooms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zhouj\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:684: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original dataset\n",
      "train acc 0.4246666666666667 test acc 0.39361702127659576\n",
      "Nicotine\n",
      "original dataset\n",
      "train acc 0.3604617604617605 test acc 0.2712765957446808\n"
     ]
    }
   ],
   "source": [
    "for i in range(11):\n",
    "    print(drugs_to_consider[i])\n",
    "    ori_df = original_df[i]\n",
    "    ori_df_X = ori_df[:,:22]\n",
    "    ori_df_y = ori_df[:,-1]\n",
    "    # train_test split\n",
    "    X_dev_ori,X_test_ori,y_dev_ori,y_test_ori = split(ori_df_X, ori_df_y)\n",
    "    \n",
    "    # scale\n",
    "    scaler_ori = StandardScaler()\n",
    "    X_dev_ori = scaler_ori.fit_transform(X_dev_ori)\n",
    "    X_test_ori = scaler_ori.transform(X_test_ori)\n",
    "    \n",
    "    # SMOTE on dev data\n",
    "    try:\n",
    "        X_dev_ori, y_dev_ori = SMOTE(random_state=42).fit_resample(X_dev_ori, y_dev_ori)\n",
    "    except ValueError:\n",
    "        1\n",
    "\n",
    "    # cv\n",
    "    log_hyperpara_dict = dict(C=uniform(loc=0.00001,scale=4.99999))\n",
    "    log_gdcv = RandomizedSearchCV(LogisticRegression(random_state=0,max_iter=1000,\\\n",
    "                                               class_weight='balanced'),log_hyperpara_dict,cv=10)\n",
    "    log_gd_search = log_gdcv.fit(X_dev_ori,y_dev_ori)\n",
    "    \n",
    "    # fit best hyper params\n",
    "    logistic_ori = LogisticRegression(C = log_gd_search.best_params_['C'], \\\n",
    "                                      random_state = 0,max_iter=1000,class_weight='balanced')\n",
    "    logistic_ori.fit(X_dev_ori,y_dev_ori)\n",
    "    print(\"original dataset\")\n",
    "    print('train acc',logistic_ori.score(X_dev_ori,y_dev_ori),'test acc',logistic_ori.score(X_test_ori,y_test_ori))\n",
    "    \n",
    "    # look into alcohol specific results\n",
    "    if i == 0:\n",
    "        y_test_ori_pred = logistic_ori.predict(X_test_ori)\n",
    "        print('test confusion matrix\\n',metrics.confusion_matrix(y_test_ori, y_test_ori_pred))\n",
    "        print('test macro F1', metrics.f1_score(y_test_ori, y_test_ori_pred, average='macro'))\n",
    "        print('test micro F1', metrics.f1_score(y_test_ori, y_test_ori_pred, average='micro'))\n",
    "        print('test weighted F1', metrics.f1_score(y_test_ori, y_test_ori_pred, average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0691d929",
   "metadata": {},
   "source": [
    "## Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5bd243ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = [200, 300, 500, 1000]\n",
    "max_features = [None, 'sqrt']\n",
    "max_depth = [int(x) for x in np.linspace(5, 100, num = 5)]\n",
    "max_depth.append(None)\n",
    "min_samples_split = [2, 5, 10]\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "bootstrap = [True, False]\n",
    "rf_random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "195bb14f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alcohol\n",
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
      "{'n_estimators': 300, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'max_depth': 52, 'bootstrap': False}\n",
      "original dataset\n",
      "train acc 1.0 test acc 0.35106382978723405\n",
      "test confusion matrix\n",
      " [[ 0  0  0  0  0  5  2]\n",
      " [ 0  0  1  0  1  4  1]\n",
      " [ 0  0  1  2  2  7  0]\n",
      " [ 1  1  2  5  6 17 10]\n",
      " [ 1  3  2  5 10 31 12]\n",
      " [ 1  1  5 13 13 85 34]\n",
      " [ 0  2  0  2  6 51 31]]\n",
      "test macro F1 0.17879662506534993\n",
      "test micro F1 0.35106382978723405\n",
      "test weighted F1 0.33092873574521836\n",
      "Caff\n",
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
      "{'n_estimators': 300, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'max_depth': 52, 'bootstrap': False}\n",
      "original dataset\n",
      "train acc 1.0 test acc 0.699468085106383\n",
      "Cannabis\n",
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
      "{'n_estimators': 300, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'max_depth': 52, 'bootstrap': False}\n",
      "original dataset\n",
      "train acc 1.0 test acc 0.39095744680851063\n",
      "Choc\n",
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zhouj\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:684: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=3.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 1000, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': None, 'max_depth': 5, 'bootstrap': True}\n",
      "original dataset\n",
      "train acc 0.56 test acc 0.4015957446808511\n",
      "Coke\n",
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
      "{'n_estimators': 300, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'max_depth': 52, 'bootstrap': False}\n",
      "original dataset\n",
      "train acc 0.9998236331569665 test acc 0.550531914893617\n",
      "Crack\n",
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zhouj\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:684: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=3.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 300, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'max_depth': 5, 'bootstrap': False}\n",
      "original dataset\n",
      "train acc 0.8633333333333333 test acc 0.8670212765957447\n",
      "Ecstasy\n",
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
      "{'n_estimators': 300, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'max_depth': 52, 'bootstrap': False}\n",
      "original dataset\n",
      "train acc 0.9998216515070447 test acc 0.5452127659574468\n",
      "Heroin\n",
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
      "{'n_estimators': 300, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'max_depth': 52, 'bootstrap': False}\n",
      "original dataset\n",
      "train acc 1.0 test acc 0.8138297872340425\n",
      "LSD\n",
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
      "{'n_estimators': 300, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'max_depth': 52, 'bootstrap': False}\n",
      "original dataset\n",
      "train acc 1.0 test acc 0.5718085106382979\n",
      "Mushrooms\n",
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
      "{'n_estimators': 500, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'max_depth': 52, 'bootstrap': True}\n",
      "original dataset\n",
      "train acc 0.9086666666666666 test acc 0.5398936170212766\n",
      "Nicotine\n",
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
      "{'n_estimators': 300, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'max_depth': 52, 'bootstrap': False}\n",
      "original dataset\n",
      "train acc 1.0 test acc 0.31648936170212766\n"
     ]
    }
   ],
   "source": [
    "for i in range(11):\n",
    "    print(drugs_to_consider[i])\n",
    "    ori_df = original_df[i]\n",
    "    ori_df_X = ori_df[:,:22]\n",
    "    ori_df_y = ori_df[:,-1]\n",
    "    # train_test split\n",
    "    X_dev_ori,X_test_ori,y_dev_ori,y_test_ori = split(ori_df_X, ori_df_y)\n",
    "    \n",
    "    # SMOTE on dev data\n",
    "    try:\n",
    "        X_dev_ori, y_dev_ori = SMOTE(random_state=42).fit_resample(X_dev_ori, y_dev_ori)\n",
    "    except ValueError:\n",
    "        1\n",
    "\n",
    "    rf_random = RandomizedSearchCV(estimator = RandomForestClassifier(random_state = 42),\\\n",
    "                                   param_distributions = rf_random_grid,\\\n",
    "                                   n_iter = 20, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
    "\n",
    "    rf_random.fit(X_dev_ori, y_dev_ori)\n",
    "    bp = rf_random.best_params_\n",
    "    print(bp)\n",
    "\n",
    "    rf_best = RandomForestClassifier(n_estimators = bp['n_estimators'], \n",
    "                                    min_samples_split = bp['min_samples_split'],\n",
    "                                    min_samples_leaf = bp['min_samples_leaf'],\n",
    "                                    max_features = bp['max_features'],\n",
    "                                    max_depth = bp['max_depth'],\n",
    "                                    bootstrap = bp['bootstrap'],\n",
    "                                    random_state = 42)\n",
    "    rf_best.fit(X_dev_ori, y_dev_ori)\n",
    "    print(\"original dataset\")\n",
    "    print('train acc',rf_best.score(X_dev_ori,y_dev_ori),'test acc',rf_best.score(X_test_ori,y_test_ori))\n",
    "    \n",
    "    # look into alcohol specific results\n",
    "    if i == 0:\n",
    "        y_test_ori_pred = rf_best.predict(X_test_ori)\n",
    "        print('test confusion matrix\\n',metrics.confusion_matrix(y_test_ori, y_test_ori_pred))\n",
    "        print('test macro F1', metrics.f1_score(y_test_ori, y_test_ori_pred, average='macro'))\n",
    "        print('test micro F1', metrics.f1_score(y_test_ori, y_test_ori_pred, average='micro'))\n",
    "        print('test weighted F1', metrics.f1_score(y_test_ori, y_test_ori_pred, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f22cb8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4db0f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
