{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2109a54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "import time\n",
    "from sklearn.preprocessing import OrdinalEncoder,OneHotEncoder\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc85277c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "def fxn():\n",
    "    warnings.warn(\"deprecated\", DeprecationWarning)\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    fxn()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70429a69",
   "metadata": {},
   "source": [
    "## Two datasets\n",
    "\n",
    "1. Original unencoded. We would scale and encode in our own methods.\n",
    "\n",
    "2. Encoded numerical. We would use it as a comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f48478d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of original dataset:  (1884, 32)\n",
      "Shape of quantified dataset:  (1884, 32)\n"
     ]
    }
   ],
   "source": [
    "df_original = pd.read_csv(\"Drug_Consumption.csv\")\n",
    "df_quantified = pd.read_csv(\"Drug_Consumption_Quantified.csv\")\n",
    "\n",
    "print(\"Shape of original dataset: \", df_original.shape)\n",
    "print(\"Shape of quantified dataset: \", df_quantified.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "761235b9",
   "metadata": {},
   "source": [
    "## Quantified dataset preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "794fef43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1876, 30)\n"
     ]
    }
   ],
   "source": [
    "df = df_quantified.drop(['ID'],axis=1)\n",
    "df = df[df['Semer']=='CL0']\n",
    "df = df.drop(['Semer'],axis=1)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7dda565c",
   "metadata": {},
   "outputs": [],
   "source": [
    "drugs_to_ignore = ['Amphet', 'Amyl', 'Benzos', 'Ketamine', 'Legalh', 'Meth', 'VSA']\n",
    "drugs_to_consider = ['Alcohol', 'Caff', 'Cannabis', 'Choc', 'Coke', 'Crack', 'Ecstasy', 'Heroin', 'LSD', 'Mushrooms', 'Nicotine']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "220d8fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_alcohol_feature = drugs_to_ignore + ['Caff', 'Cannabis', 'Choc', 'Coke', 'Crack', 'Ecstasy', 'Heroin', 'LSD', 'Mushrooms', 'Nicotine']\n",
    "non_caff_features = drugs_to_ignore + ['Alcohol', 'Cannabis', 'Choc', 'Coke', 'Crack', 'Ecstasy', 'Heroin', 'LSD', 'Mushrooms', 'Nicotine']\n",
    "non_cannabis_features = drugs_to_ignore + ['Alcohol', 'Caff', 'Choc', 'Coke', 'Crack', 'Ecstasy', 'Heroin', 'LSD', 'Mushrooms', 'Nicotine']\n",
    "non_choc_features = drugs_to_ignore + ['Alcohol', 'Caff', 'Cannabis', 'Coke', 'Crack', 'Ecstasy', 'Heroin', 'LSD', 'Mushrooms', 'Nicotine']\n",
    "non_coke_features = drugs_to_ignore + ['Alcohol', 'Caff', 'Cannabis', 'Choc', 'Crack', 'Ecstasy', 'Heroin', 'LSD', 'Mushrooms', 'Nicotine']\n",
    "non_crack_features = drugs_to_ignore + ['Alcohol', 'Caff', 'Cannabis', 'Choc', 'Coke', 'Ecstasy', 'Heroin', 'LSD', 'Mushrooms', 'Nicotine']\n",
    "non_ecstasy_features = drugs_to_ignore + ['Alcohol', 'Caff', 'Cannabis', 'Choc', 'Coke', 'Crack', 'Heroin', 'LSD', 'Mushrooms', 'Nicotine']\n",
    "non_heroin_features = drugs_to_ignore + ['Alcohol', 'Caff', 'Cannabis', 'Choc', 'Coke', 'Crack', 'Ecstasy', 'LSD', 'Mushrooms', 'Nicotine']\n",
    "non_lsd_features = drugs_to_ignore + ['Alcohol', 'Caff', 'Cannabis', 'Choc', 'Coke', 'Crack', 'Ecstasy', 'Heroin', 'Mushrooms', 'Nicotine']\n",
    "non_mushrooms_features = drugs_to_ignore + ['Alcohol', 'Caff', 'Cannabis', 'Choc', 'Coke', 'Crack', 'Ecstasy', 'Heroin', 'LSD', 'Nicotine']\n",
    "non_nicotine_features = drugs_to_ignore + ['Alcohol', 'Caff', 'Cannabis', 'Choc', 'Coke', 'Crack', 'Ecstasy', 'Heroin', 'LSD', 'Mushrooms']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9507b3a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "drug_enc=OrdinalEncoder(categories=[[\"CL0\",\"CL1\",\"CL2\",\"CL3\",\"CL4\",\"CL5\",\"CL6\"]])\n",
    "for feature in drugs_to_consider:\n",
    "    df[feature]=drug_enc.fit_transform(df[feature].to_numpy().reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c94db373",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_quan_alcohol = df.drop(non_alcohol_feature, axis = 1)\n",
    "\n",
    "df_quan_caff = df.drop(non_caff_features, axis = 1)\n",
    "\n",
    "df_quan_cannabis = df.drop(non_cannabis_features, axis = 1)\n",
    "\n",
    "df_quan_choc = df.drop(non_choc_features, axis = 1)\n",
    "\n",
    "df_quan_coke = df.drop(non_coke_features, axis = 1)\n",
    "\n",
    "df_quan_crack = df.drop(non_crack_features, axis = 1)\n",
    "\n",
    "df_quan_ecstasy = df.drop(non_ecstasy_features, axis = 1)\n",
    "\n",
    "df_quan_heroin = df.drop(non_heroin_features, axis = 1)\n",
    "\n",
    "df_quan_lsd = df.drop(non_lsd_features, axis = 1)\n",
    "\n",
    "df_quan_mushrooms = df.drop(non_mushrooms_features, axis = 1)\n",
    "\n",
    "df_quan_nicotine = df.drop(non_nicotine_features, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "81ed7605",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Education</th>\n",
       "      <th>Country</th>\n",
       "      <th>Ethnicity</th>\n",
       "      <th>Nscore</th>\n",
       "      <th>Escore</th>\n",
       "      <th>Oscore</th>\n",
       "      <th>AScore</th>\n",
       "      <th>Cscore</th>\n",
       "      <th>Impulsive</th>\n",
       "      <th>SS</th>\n",
       "      <th>Nicotine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.07854</td>\n",
       "      <td>-0.48246</td>\n",
       "      <td>1.98437</td>\n",
       "      <td>0.96082</td>\n",
       "      <td>-0.31685</td>\n",
       "      <td>-0.67825</td>\n",
       "      <td>1.93886</td>\n",
       "      <td>1.43533</td>\n",
       "      <td>0.76096</td>\n",
       "      <td>-0.14277</td>\n",
       "      <td>-0.71126</td>\n",
       "      <td>-0.21575</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.49788</td>\n",
       "      <td>-0.48246</td>\n",
       "      <td>-0.05921</td>\n",
       "      <td>0.96082</td>\n",
       "      <td>-0.31685</td>\n",
       "      <td>-0.46725</td>\n",
       "      <td>0.80523</td>\n",
       "      <td>-0.84732</td>\n",
       "      <td>-1.62090</td>\n",
       "      <td>-1.01450</td>\n",
       "      <td>-1.37983</td>\n",
       "      <td>0.40148</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.95197</td>\n",
       "      <td>0.48246</td>\n",
       "      <td>1.16365</td>\n",
       "      <td>0.96082</td>\n",
       "      <td>-0.31685</td>\n",
       "      <td>-0.14882</td>\n",
       "      <td>-0.80615</td>\n",
       "      <td>-0.01928</td>\n",
       "      <td>0.59042</td>\n",
       "      <td>0.58489</td>\n",
       "      <td>-1.37983</td>\n",
       "      <td>-1.18084</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.49788</td>\n",
       "      <td>0.48246</td>\n",
       "      <td>1.98437</td>\n",
       "      <td>0.96082</td>\n",
       "      <td>-0.31685</td>\n",
       "      <td>0.73545</td>\n",
       "      <td>-1.63340</td>\n",
       "      <td>-0.45174</td>\n",
       "      <td>-0.30172</td>\n",
       "      <td>1.30612</td>\n",
       "      <td>-0.21712</td>\n",
       "      <td>-0.21575</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.59171</td>\n",
       "      <td>0.48246</td>\n",
       "      <td>-1.22751</td>\n",
       "      <td>0.24923</td>\n",
       "      <td>-0.31685</td>\n",
       "      <td>-0.67825</td>\n",
       "      <td>-0.30033</td>\n",
       "      <td>-1.55521</td>\n",
       "      <td>2.03972</td>\n",
       "      <td>1.63088</td>\n",
       "      <td>-1.37983</td>\n",
       "      <td>-1.54858</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Age   Gender  Education  Country  Ethnicity   Nscore   Escore   Oscore  \\\n",
       "0 -0.07854 -0.48246    1.98437  0.96082   -0.31685 -0.67825  1.93886  1.43533   \n",
       "1  0.49788 -0.48246   -0.05921  0.96082   -0.31685 -0.46725  0.80523 -0.84732   \n",
       "2 -0.95197  0.48246    1.16365  0.96082   -0.31685 -0.14882 -0.80615 -0.01928   \n",
       "3  0.49788  0.48246    1.98437  0.96082   -0.31685  0.73545 -1.63340 -0.45174   \n",
       "4  2.59171  0.48246   -1.22751  0.24923   -0.31685 -0.67825 -0.30033 -1.55521   \n",
       "\n",
       "    AScore   Cscore  Impulsive       SS  Nicotine  \n",
       "0  0.76096 -0.14277   -0.71126 -0.21575       4.0  \n",
       "1 -1.62090 -1.01450   -1.37983  0.40148       0.0  \n",
       "2  0.59042  0.58489   -1.37983 -1.18084       2.0  \n",
       "3 -0.30172  1.30612   -0.21712 -0.21575       2.0  \n",
       "4  2.03972  1.63088   -1.37983 -1.54858       6.0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_quan_nicotine.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0493678c",
   "metadata": {},
   "source": [
    "## Original dataset preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "19b8b555",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1876, 23)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = df_original.drop(['ID'],axis=1)\n",
    "df1 = df1[df1['Semer']=='CL0']\n",
    "df1 = df1.drop(['Semer'],axis=1)\n",
    "df1 = df1.drop(drugs_to_ignore,axis=1)\n",
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "88fb09b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_feature = ['Nscore','Escore','Oscore','AScore','Cscore','Impulsive','SS']\n",
    "nominal_cat_feature=[\"Gender\",\"Country\",\"Ethnicity\"] ##apply onehot encoder to encode nominal categorical features\n",
    "\n",
    "## apply ordinalecoder to encode ordinal categorical features and target values.\n",
    "age_enc=OrdinalEncoder(categories=[[\"18-24\",\"25-34\",\"35-44\",\"45-54\",\"55-64\",\"65+\"]])\n",
    "edu_enc=OrdinalEncoder(categories=[[\"Left school before 16 years\",\"Left school at 16 years\",\"Left school at 17 years\",\"Left school at 18 years\",\"Some college or university, no certificate or degree\",\"Professional certificate/ diploma\",\"University degree\",\"Masters degree\",\"Doctorate degree\"]])\n",
    "drug_enc=OrdinalEncoder(categories=[[\"CL0\",\"CL1\",\"CL2\",\"CL3\",\"CL4\",\"CL5\",\"CL6\"]])\n",
    "\n",
    "## ordinal encoder seems not encode multiple varibles at same time, so encode targets values one by one first.\n",
    "for feature in drugs_to_consider:\n",
    "    df1[feature] = drug_enc.fit_transform(df1[feature].to_numpy().reshape(-1,1))\n",
    "\n",
    "preprocess=make_column_transformer((StandardScaler(),numerical_feature),\n",
    "                                   (age_enc,[\"Age\"]),\n",
    "                                   (edu_enc, [\"Education\"]),\n",
    "                                   (OneHotEncoder(handle_unknown=\"ignore\",drop='first'),nominal_cat_feature),\n",
    "                                   remainder=\"passthrough\")\n",
    "df_trans = preprocess.fit_transform(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3ba3c71e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1876, 33)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_trans.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2120a0ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1876, 22)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ori_X = df_trans[:,:22]\n",
    "df_ori_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7721d6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ori_alcohol = np.c_[df_ori_X,df_trans[:,22]]\n",
    "\n",
    "df_ori_caff = np.c_[df_ori_X,df_trans[:,23]]\n",
    "\n",
    "df_ori_cannabis = np.c_[df_ori_X,df_trans[:,24]]\n",
    "\n",
    "df_ori_choc = np.c_[df_ori_X,df_trans[:,25]]\n",
    "\n",
    "df_ori_coke = np.c_[df_ori_X,df_trans[:,26]]\n",
    "\n",
    "df_ori_crack = np.c_[df_ori_X,df_trans[:,27]]\n",
    "\n",
    "df_ori_ecstasy = np.c_[df_ori_X,df_trans[:,28]]\n",
    "\n",
    "df_ori_heroin = np.c_[df_ori_X,df_trans[:,29]]\n",
    "\n",
    "df_ori_lsd = np.c_[df_ori_X,df_trans[:,30]]\n",
    "\n",
    "df_ori_mushrooms = np.c_[df_ori_X,df_trans[:,31]]\n",
    "\n",
    "df_ori_nicotine = np.c_[df_ori_X,df_trans[:,32]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2933cebf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1876, 23)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ori_alcohol.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50989268",
   "metadata": {},
   "source": [
    "## modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9316c091",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(df_X, df_Y):\n",
    "    X_dev, X_test, y_dev, y_test = train_test_split(df_X, df_Y, test_size=0.2, random_state=42)\n",
    "    return X_dev,X_test,y_dev,y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cd019fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "quantified_df = [df_quan_alcohol, df_quan_caff, df_quan_cannabis, df_quan_choc, df_quan_coke, df_quan_crack,\\\n",
    "                  df_quan_ecstasy, df_quan_heroin, df_quan_lsd, df_quan_mushrooms, df_quan_nicotine]\n",
    "original_df = [df_ori_alcohol, df_ori_caff, df_ori_cannabis, df_ori_choc, df_ori_coke, df_ori_crack,\\\n",
    "                  df_ori_ecstasy, df_ori_heroin, df_ori_lsd, df_ori_mushrooms, df_ori_nicotine]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e3f7181",
   "metadata": {},
   "source": [
    "## Baseline Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e393c746",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alcohol\n",
      "quantified dataset\n",
      "train acc 0.712 test acc 0.31648936170212766\n",
      "test confusion matrix\n",
      " [[ 1  0  0  0  0  4  2]\n",
      " [ 0  1  0  0  0  4  2]\n",
      " [ 0  0  0  1  2  6  3]\n",
      " [ 2  1  2  2  7 17 11]\n",
      " [ 2  1  1  3 10 38  9]\n",
      " [ 2  2  7  9 15 82 35]\n",
      " [ 2  0  2  4  8 53 23]]\n",
      "original dataset\n",
      "train acc 0.694 test acc 0.3351063829787234\n",
      "test confusion matrix\n",
      " [[ 1  0  0  0  0  5  1]\n",
      " [ 0  0  1  0  0  5  1]\n",
      " [ 0  1  0  0  1  6  4]\n",
      " [ 1  1  2  5 11 13  9]\n",
      " [ 0  1  0  5 11 32 15]\n",
      " [ 2  2  4 10 12 83 39]\n",
      " [ 0  0  1  4  7 54 26]]\n",
      "Caff\n",
      "quantified dataset\n",
      "train acc 0.7853333333333333 test acc 0.6781914893617021\n",
      "test confusion matrix\n",
      " [[  1   0   0   0   0   0   4]\n",
      " [  0   0   0   0   0   0   1]\n",
      " [  0   0   0   0   0   0   5]\n",
      " [  0   0   0   0   0   0  15]\n",
      " [  0   0   1   0   0   1  19]\n",
      " [  1   1   2   0   2  10  37]\n",
      " [  1   1   3   0   4  23 244]]\n",
      "original dataset\n",
      "train acc 0.832 test acc 0.651595744680851\n",
      "test confusion matrix\n",
      " [[  0   0   0   0   0   0   5]\n",
      " [  0   0   0   0   0   0   1]\n",
      " [  0   0   0   0   0   0   5]\n",
      " [  0   0   1   0   0   0  14]\n",
      " [  0   0   0   0   0   3  18]\n",
      " [  0   0   1   1   0  11  40]\n",
      " [  0   2   2   4   5  29 234]]\n",
      "Cannabis\n",
      "quantified dataset\n",
      "train acc 0.7366666666666667 test acc 0.35638297872340424\n",
      "test confusion matrix\n",
      " [[51 15 18  4  1  3  2]\n",
      " [15 17  8  2  1  1  3]\n",
      " [12  6 10  8  4  2  9]\n",
      " [10  4  6  1  1  2  7]\n",
      " [ 1  0  2  3  3  3 15]\n",
      " [ 0  2  2  4  3  4 15]\n",
      " [ 9  7 12  8  2 10 48]]\n",
      "original dataset\n",
      "train acc 0.736 test acc 0.34308510638297873\n",
      "test confusion matrix\n",
      " [[36 13 31  7  1  2  4]\n",
      " [16 16  9  1  1  0  4]\n",
      " [ 9  3 15  8  3  4  9]\n",
      " [ 7  3 10  1  1  2  7]\n",
      " [ 1  0  2  2  4  4 14]\n",
      " [ 0  2  2  2  3  6 15]\n",
      " [ 9  8 10  7  4  7 51]]\n",
      "Choc\n",
      "quantified dataset\n",
      "train acc 0.6933333333333334 test acc 0.36436170212765956\n",
      "test confusion matrix\n",
      " [[ 0  0  0  0  4  3]\n",
      " [ 0  0  0  0  0  2]\n",
      " [ 0  0  0  1  3  7]\n",
      " [ 1  0  1  7 17 25]\n",
      " [ 2  0  0 13 44 76]\n",
      " [ 2  0  3 13 66 86]]\n",
      "original dataset\n",
      "train acc 0.6966666666666667 test acc 0.3882978723404255\n",
      "test confusion matrix\n",
      " [[ 1  0  0  1  5  0]\n",
      " [ 0  0  0  0  0  2]\n",
      " [ 0  0  0  1  3  7]\n",
      " [ 0  0  1  8 22 20]\n",
      " [ 0  0  0 13 53 69]\n",
      " [ 2  0  2 15 67 84]]\n",
      "Coke\n",
      "quantified dataset\n",
      "train acc 0.8433333333333334 test acc 0.5053191489361702\n",
      "test confusion matrix\n",
      " [[162  12  24  16   7   2   2]\n",
      " [ 16   9   7   4   0   0   0]\n",
      " [ 25   3  12   8   3   0   1]\n",
      " [ 21   1   6   7   3   1   2]\n",
      " [  4   1   8   5   0   0   0]\n",
      " [  1   1   0   1   0   0   0]\n",
      " [  1   0   0   0   0   0   0]]\n",
      "original dataset\n",
      "train acc 0.8393333333333334 test acc 0.5319148936170213\n",
      "test confusion matrix\n",
      " [[171   5  29  13   3   3   1]\n",
      " [ 17   9   8   2   0   0   0]\n",
      " [ 26   3  15   6   2   0   0]\n",
      " [ 19   3   8   5   3   2   1]\n",
      " [  7   0   6   5   0   0   0]\n",
      " [  2   0   0   1   0   0   0]\n",
      " [  1   0   0   0   0   0   0]]\n",
      "Crack\n",
      "quantified dataset\n",
      "train acc 0.9426666666666667 test acc 0.8031914893617021\n",
      "test confusion matrix\n",
      " [[298   1  17   5   2   3]\n",
      " [ 16   1   4   0   0   0]\n",
      " [ 15   3   2   0   0   1]\n",
      " [  5   0   1   1   0   0]\n",
      " [  1   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0]]\n",
      "original dataset\n",
      "train acc 0.95 test acc 0.7872340425531915\n",
      "test confusion matrix\n",
      " [[293   4  17   7   0   5]\n",
      " [ 16   1   4   0   0   0]\n",
      " [ 15   4   2   0   0   0]\n",
      " [  6   0   1   0   0   0]\n",
      " [  1   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0]]\n",
      "Ecstasy\n",
      "quantified dataset\n",
      "train acc 0.8173333333333334 test acc 0.5053191489361702\n",
      "test confusion matrix\n",
      " [[164  12  16  19   7   0   0]\n",
      " [ 16   1   6   1   1   1   0]\n",
      " [ 19   3  10   9   4   0   0]\n",
      " [ 20   1   5  10   4   3   0]\n",
      " [  9   1   1   9   5   0   1]\n",
      " [  4   1   1   4   2   0   0]\n",
      " [  1   0   1   2   1   1   0]]\n",
      "original dataset\n",
      "train acc 0.8153333333333334 test acc 0.523936170212766\n",
      "test confusion matrix\n",
      " [[168  11  13  19   7   0   0]\n",
      " [ 17   1   4   1   1   2   0]\n",
      " [ 18   2  14   9   2   0   0]\n",
      " [ 21   1   6   9   4   2   0]\n",
      " [  8   1   3   9   5   0   0]\n",
      " [  4   0   2   4   2   0   0]\n",
      " [  1   0   1   3   0   1   0]]\n",
      "Heroin\n",
      "quantified dataset\n",
      "train acc 0.9413333333333334 test acc 0.824468085106383\n",
      "test confusion matrix\n",
      " [[308   2   5   7   2   3   0]\n",
      " [ 17   1   1   0   1   0   0]\n",
      " [ 11   1   1   1   0   0   0]\n",
      " [ 10   0   2   0   0   0   1]\n",
      " [  0   0   0   0   0   0   0]\n",
      " [  1   0   0   0   0   0   0]\n",
      " [  1   0   0   0   0   0   0]]\n",
      "original dataset\n",
      "train acc 0.932 test acc 0.8351063829787234\n",
      "test confusion matrix\n",
      " [[309   1   6   7   1   3   0]\n",
      " [ 17   1   1   1   0   0   0]\n",
      " [  9   0   4   1   0   0   0]\n",
      " [ 13   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0]\n",
      " [  1   0   0   0   0   0   0]\n",
      " [  1   0   0   0   0   0   0]]\n",
      "LSD\n",
      "quantified dataset\n",
      "train acc 0.8186666666666667 test acc 0.5053191489361702\n",
      "test confusion matrix\n",
      " [[162  13  13  22   2   1   0]\n",
      " [ 31  15   9   2   2   0   0]\n",
      " [ 15   6   7   7   0   0   1]\n",
      " [ 18   2   7   6   1   4   1]\n",
      " [  7   3   3   7   0   0   0]\n",
      " [  4   1   0   3   0   0   0]\n",
      " [  0   0   0   0   0   1   0]]\n",
      "original dataset\n",
      "train acc 0.8186666666666667 test acc 0.5186170212765957\n",
      "test confusion matrix\n",
      " [[166  13  12  19   2   1   0]\n",
      " [ 28  17  10   2   2   0   0]\n",
      " [ 16   6   6   7   0   0   1]\n",
      " [ 18   2   7   6   1   4   1]\n",
      " [  7   3   1   9   0   0   0]\n",
      " [  4   1   0   3   0   0   0]\n",
      " [  0   0   0   0   0   1   0]]\n",
      "Mushrooms\n",
      "quantified dataset\n",
      "train acc 0.81 test acc 0.5132978723404256\n",
      "test confusion matrix\n",
      " [[145  18  21  11   6   0]\n",
      " [ 19  14   3   2   1   0]\n",
      " [ 18  10  14  13   2   0]\n",
      " [ 13   1   3  17  10   1]\n",
      " [  7   2   4  10   3   2]\n",
      " [  1   0   0   3   2   0]]\n",
      "original dataset\n",
      "train acc 0.81 test acc 0.5106382978723404\n",
      "test confusion matrix\n",
      " [[145  15  20  14   7   0]\n",
      " [ 21  13   1   2   2   0]\n",
      " [ 17  11  12  14   3   0]\n",
      " [ 11   1   4  19   9   1]\n",
      " [  8   2   4   9   3   2]\n",
      " [  1   0   0   3   2   0]]\n",
      "Nicotine\n",
      "quantified dataset\n",
      "train acc 0.694 test acc 0.324468085106383\n",
      "test confusion matrix\n",
      " [[47 12  4  9  3  3 13]\n",
      " [15 13  3  2  1  1 12]\n",
      " [21  8  5  2  1  2 16]\n",
      " [ 6  5  0  4  0  5  8]\n",
      " [ 4  0  1  2  2  0 11]\n",
      " [ 6  0  2  3  0  3  9]\n",
      " [26  8 12  6  4  8 48]]\n",
      "original dataset\n",
      "train acc 0.6893333333333334 test acc 0.32180851063829785\n",
      "test confusion matrix\n",
      " [[47  9  8  9  4  2 12]\n",
      " [16 12  4  1  0  0 14]\n",
      " [21  8  4  4  1  0 17]\n",
      " [ 6  5  0  5  1  3  8]\n",
      " [ 3  1  1  2  3  0 10]\n",
      " [ 6  1  2  1  0  2 11]\n",
      " [25 11 10  6  5  7 48]]\n"
     ]
    }
   ],
   "source": [
    "for i in range(11):\n",
    "    print(drugs_to_consider[i])\n",
    "    quan_df = quantified_df[i]\n",
    "    ori_df = original_df[i]\n",
    "    quan_df_X = quan_df.drop(columns=[drugs_to_consider[i]])\n",
    "    quan_df_y = quan_df[drugs_to_consider[i]]\n",
    "    ori_df_X = ori_df[:,:22]\n",
    "    ori_df_y = ori_df[:,-1]\n",
    "    X_dev_quan,X_test_quan,y_dev_quan,y_test_quan = split(quan_df_X, quan_df_y)\n",
    "    X_dev_ori,X_test_ori,y_dev_ori,y_test_ori = split(ori_df_X, ori_df_y)\n",
    "    dtclf_quan = DecisionTreeClassifier(random_state = 0, max_depth = 10)\n",
    "    dtclf_quan.fit(X_dev_quan,y_dev_quan)\n",
    "    print(\"quantified dataset\")\n",
    "    print('train acc',dtclf_quan.score(X_dev_quan,y_dev_quan),'test acc',dtclf_quan.score(X_test_quan,y_test_quan))\n",
    "    y_test_quan_pred = dtclf_quan.predict(X_test_quan)\n",
    "    print('test confusion matrix\\n',metrics.confusion_matrix(y_test_quan, y_test_quan_pred))\n",
    "    dtclf_ori = DecisionTreeClassifier(random_state = 0, max_depth = 10)\n",
    "    dtclf_ori.fit(X_dev_ori,y_dev_ori)\n",
    "    print(\"original dataset\")\n",
    "    print('train acc',dtclf_ori.score(X_dev_ori,y_dev_ori),'test acc',dtclf_ori.score(X_test_ori,y_test_ori))\n",
    "    y_test_ori_pred = dtclf_ori.predict(X_test_ori)\n",
    "    print('test confusion matrix\\n',metrics.confusion_matrix(y_test_ori, y_test_ori_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d39aa6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5206124",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195bb14f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c5ed2f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
